<h2>문제 인식</h2><p>Edukit 서비스는 중·고등 교사들의 업무 부담을 줄여주는 것을 목표로 하며, 그중 하나로 <b>생기부 작성 보조 기능</b>을 제공하고 있다. 이 기능은 생기부 마감 시기인 6월 말 ~ 7월 초에 맞춰 빠르게 개발·배포되었고, 다행히 많은 1차 사용자들을 확보할 수 있었다.</p><figure class="imageblock widthContent"><span><img height="1394" src="https://blog.kakaocdn.net/dn/bPcREO/btsQcW6Onlr/4HT7uPolsDVbSTWLmFFGWk/img.png" width="2488" /></span></figure>
<p>그 과정에서 다양한 피드백을 받았는데, 그중 가장 주목한 부분은 AI가 생성하는 생기부 응답의 품질이었다. 경쟁 서비스가 존재하는 만큼 Edukit이 차별화해야 할 요소는 가격과 품질이라고 보았다. 그러나 1차 MVP는 약 2주라는 짧은 개발 기간 안에 완성해야 했기 때문에, 단일 프롬프트 + 1회 호출 구조로 생기부 응답을 생성하는 방식에 의존할 수밖에 없었다.</p><figure class="imageblock widthContent"><span><img height="1690" src="https://blog.kakaocdn.net/dn/Z3ZiV/btsQbxNH077/y0B4Ti4KQme0daCIKb0Ou1/img.png" width="2724" /></span><figcaption>단일 프롬프팅의 흔적..</figcaption>
</figure>
<p>이 방식은 여러 제약 조건<span style="color: #666666;">(금지어 사용 제한, 부정 표현 금지, 수상 기록 배제, 음슴체 사용 등)</span>을 한 번의 프롬프트로 처리해야 했기 때문에 모든 규칙을 일관되게 반영하기 어려웠다. 실제 사용자 피드백에서도 대체로 만족한다는 응답이 많았으나, 품질이 일관되지 않다는 지적이 꾸준히 있었다. 특히 가장 큰 문제는 사용자가 학생의 활동을 여러 단락으로 입력할 경우, 첫 번째 단락만 반영된 채 응답이 생성되는 오류였다.<br />우리는 그 원인을 "너무 많은 제약 조건을 단일 프롬프트에 담으려다 보니 정확도가 떨어진 것"이라는 가설로 세웠고, 실제 GPT 테스트 과정에서 이를 어느 정도 검증할 수 있었다. 이에 따라 기존의 단일 프롬프트 구조에서 벗어나, A2A 기반의 Multi-Agent AI 파이프라인을 도입하여 생기부 응답의 품질을 강화하기로 결정했다.</p><h2>Agent-to-Agent 방식이란?</h2><p>A2A는 간단히 말해 <b>하나의 AI가 모든 걸 다 처리하는 대신, 여러 AI가 서로 협력하며 단계적으로 문제를 해결하는 방식</b>이다.</p><figure class="imageblock widthContent"><span><img height="910" src="https://blog.kakaocdn.net/dn/bSVDIl/btsQaUJgyrx/kr5bnrwmtCNCkzvetwsack/img.png" width="1280" /></span></figure>
<p>기존에는 “한 번의 요청 → 한 번의 응답” 구조였다면, A2A는 “여러 요청 → 여러 AI 간 협업 → 최종 응답” 흐름을 갖는다. 예를 들어, 생기부를 생성한다고 하면, 분석 Agent가 입력된 학생 활동을 분석하고 중요한 포인트들을 정리하고, 작성 Agent가 이 분석 결과를 바탕으로 규칙에 맞는 생기부 문장을 작성하는 것이다. 마지막으로 검수 Agent가 금지어 사용, 부정 표현 여부, 문체등을 최종적으로 확인하고 교정한다. 이렇게 단계를 나누어 하나의 프롬프트에서 모든 걸 해결하려던 방식보다 훨씬 안정적이고 일관된 품질을 얻을 수 있다. 즉, 일종의 AI 버전 팀플인 것이다.</p><h2>설계해보자.</h2><p>아무래도 호출 비용과 응답 속도를 고려하다 보니, Agent의 개수는 3개로 정했다. 첫 번째 Agent는 사용자가 입력한 활동 내용을 기반으로, 생기부 작성 규칙에 얽매이지 않고 최대한 다양한 포인트를 뽑아내어 세 가지 버전의 초안을 만든다. 두 번째 Agent는 이 초안을 받아, 금지어나 부정 표현을 검수하고 생기부 작성 규칙에 맞게 다듬어 정제된 초안을 완성한다. 마지막 Agent는 이 결과를 최종적으로 사용자 입력의 바이트 수에 맞추고, 문체(예: 음슴체)를 검수한 뒤 사용자에게 반환한다. 즉, 단순히 한 번에 모든 걸 처리하는 대신, 3단계 파이프라인으로 나누어 각각의 역할을 명확히 함으로써 결과의 품질과 일관성을 확보한 것이다.</p><h3>구현 아키텍쳐와 선택의 이유</h3><figure class="imageblock widthContent"><span><img height="870" src="https://blog.kakaocdn.net/dn/bb07ln/btsQddHso0z/ZYHDKwe5KwCyKulqHUXeok/img.png" width="2048" /></span></figure>
<p>Edukit의 생기부 작성 기능은 특성상 트래픽 패턴이 매우 뚜렷하다. 평소에는 거의 요청이 없다가, 마감 시즌인 6월 말에서 7월 초에만 수많은 요청이 몰린다. 이런 워크로드 특성을 고려했을 때, 항상 서버 자원을 유지해야 하는 EC2보다는 호출 수 기반 과금 모델을 가진 AWS Lambda가 비용적으로 훨씬 유리하다고 판단했다. 특히 Lambda는 AWS에서 기본적으로 오토스케일링을 제공하기 때문에, 갑자기 트래픽이 몰리더라도 별도의 튜닝 없이 안정적으로 대응할 수 있다는 장점도 있다. 다만 모든 Agent를 Lambda로 구현하지는 않았다. 사실 첫 번째 Agent를 어디에 둘지는 고민이 많았다. 이 Agent는 사용자가 입력한 활동을 바탕으로 규칙에 얽매이지 않고 최대한 다양한 포인트를 뽑아내는 역할을 한다. 이 단계는 상대적으로 단순한 LLM 호출 위주였고, 마침 기존에 Spring AI 기반으로 구현해둔 코드가 있었기 때문에 이를 재활용하는 것이 훨씬 빠르고 현실적이었다. 서버 자원에도 여유가 있었던 만큼, 첫 번째 Agent는 그대로 Spring 애플리케이션 서버에서 실행하도록 하고, 프롬프트 처리 로직만 바꾸는 방식으로 파이프라인을 빠르게 구축할 수 있었다. 반면 두 번째와 세 번째 Agent는 검수·정제 단계라 상대적으로 부하가 크고 실행 시간이 들쭉날쭉할 수 있었기 때문에, 스레드 풀 점유나 자원 고갈을 막기 위해 Lambda로 분리하는 것이 맞다고 보았다. 이렇게 하면 각 Agent가 독립적으로 확장할 수 있어 전체적인 안정성이 높아진다.</p><h4>전체적인 흐름 - 왜 SQS를 도입했을까?</h4><p>구체적인 처리 흐름은 다음과 같다. 사용자가 생기부 생성 요청을 보내면 서버는 즉시 작업 ID를 반환하고, 실제 생기부 생성은 비동기 작업으로 전환된다. 첫 번째 Agent가 초안을 생성하면, 해당 결과와 작업 ID를 SQS 큐에 메시지로 발행한다. 이후 Lambda 함수가 이 큐를 이벤트 소스로 받아 자동으로 트리거되고, 다음 단계를 수행한다. 각 단계 사이에는 모두 SQS를 두었는데, 이는 단순한 이벤트 전달 이상의 의미가 있다.<br />가장 큰 이유는 장애 격리다. 만약 중간에 어떤 Agent가 부하로 인해 늦어지거나 장애가 발생한다면, 큐가 없다면 작업이 연쇄적으로 실패하고 장애가 파급될 수밖에 없다. 하지만 큐를 두면 메시지가 안전하게 적재되어 순차적으로 처리되므로, 처리 속도가 다소 느려지더라도 안정성이 크게 높아진다. 또한 SQS는 재시도 로직을 설정하거나, 반복 실패 시 DLQ(Dead Letter Queue) 로 메시지를 보내 로그를 남기고 알림을 발송할 수 있기 때문에, 장애 분석과 후속 대응이 훨씬 쉬워진다. 결국 각 Agent 단위로 SQS를 두는 것이 장애 전파를 막고, 안정적인 파이프라인을 운영하기 위한 핵심적인 장치였다.<br />정리하자면, Edukit은 계절성 트래픽이라는 특수성을 고려해 Lambda와 SQS 기반 아키텍처를 선택했고, 기존 코드를 활용할 수 있는 부분은 서버에 두어 개발 속도를 확보했다. 동시에 단계별로 큐를 두어 장애를 격리하고, 필요하면 재시도 및 DLQ를 활용할 수 있는 구조로 설계했다. 결과적으로 이 접근은 비용 효율성, 확장성, 안정성을 모두 확보하는 전략이 될 수 있었다.</p><h4>AWS SQS – FIFO 큐 vs Standard 큐 선택기준</h4><p>AWS SQS를 사용할 때 가장 먼저 고민해야 하는 부분 중 하나는 FIFO 큐를 선택할지, 아니면 Standard 큐를 선택할지다. 두 큐는 겉보기엔 비슷하지만, 실제로는 성능 특성과 보장하는 조건이 다르기 때문에 서비스의 요구사항에 따라 선택이 달라진다.<br />FIFO 큐는 이름 그대로 메시지 순서가 보장된다. 먼저 들어온 메시지는 반드시 먼저 처리되며, 동시에 중복 메시지가 절대 발행되지 않는다는 장점이 있다. 따라서 주문 처리, 금융 트랜잭션, 이벤트 로그 수집처럼 순서와 무결성이 중요한 시스템에서 주로 사용된다. 다만 순서를 맞추는 과정에서 처리량이 상대적으로 제한될 수 있다는 단점이 있다.<br />반면 Standard 큐는 순서를 보장하지 않는다. 같은 시점에 들어온 메시지가 어떤 순서로 소비될지는 알 수 없다. 또한 중복 메시지가 전달될 가능성이 있다. 하지만 대신 처리량(Throughput)이 훨씬 높다는 장점이 있다. 순서가 중요하지 않고, 다소의 중복을 애플리케이션 레벨에서 감당할 수 있다면 Standard 큐가 더 효율적인 선택이 된다.<br />우리 서비스에서는 생기부 자동 응답을 3가지 버전으로 생성하는데, 이때 각 버전이 어떤 순서로 도착하는지는 사용자 경험에 큰 영향을 주지 않는다. 예를 들어, 첫 번째 버전이 세 번째 버전보다 늦게 생성되더라도 사용자는 결과물을 최종적으로 확인할 수 있기 때문에 문제되지 않는다. 오히려 빠른 응답 속도와 높은 처리량이 더 중요한 포인트였다.<br />이런 이유로 우리는 Standard 큐를 선택했다. 불필요하게 순서를 강제하는 대신, 성능과 확장성에 유리한 구조를 가져가는 것이 서비스 성격에 더 잘 맞았기 때문이다.</p><hr /><p>번외) Standard 큐와 FIFO 큐와 중복 메세지</p><p>AWS SQS를 사용할 때 Standard 큐와 FIFO 큐의 가장 큰 차이 중 하나는 <b>중복 메시지 발생 여부</b>다. <b>Standard 큐는 중복 메시지가 전달될 가능성이 있다.</b> 그 이유는 SQS가 분산 환경에서 동작하기 때문이다. 메시지를 여러 서버와 노드에 분산하여 저장하고 처리하다 보니, 네트워크 지연이나 장애, 재시도 과정에서 동일한 메시지가 소비자에게 두 번 이상 전달될 수 있다. Standard 큐는 이러한 구조를 허용하면서도 <b>최소 한 번 이상 전달(at-least-once)</b>이라는 전송 보장을 제공한다. 즉, 시스템의 확장성과 처리량을 최우선으로 설계했기 때문에, 중복 가능성을 애플리케이션 레벨에서 흡수하도록 한 것이다.<br />반면 <b>FIFO 큐는 중복 메시지가 절대 발생하지 않는다.</b> 내부적으로 메시지 그룹 단위로 순서를 관리하고, 메시지를 직렬화하여 처리한다. 이미 처리된 메시지는 큐에서 제거되며, 동일 메시지가 다시 전달되지 않도록 시스템적으로 보장된다. 메시지 순서를 엄격하게 맞추고 정확하게 한 번만 전달하도록 설계했기 때문에, 중복 가능성이 근본적으로 차단된다.<br />결국 Standard 큐와 FIFO 큐의 중복 메시지 차이는 시스템 설계 철학과 내부 처리 방식에서 비롯된다. Standard 큐는 높은 처리량과 확장성을 위해 일부 중복을 허용하는 구조이고, FIFO 큐는 정확성·순서 보장을 위해 중복을 철저히 제거하는 구조다.</p><h3>멱등성을 보장해보자.</h3><p>우리 서비스에는 생성 작업을 요청하면 고유한 taskId를 반환해준다. 이는 AI 생기부 작업 테이블의 기본키 값이기 때문에 절대 중복되지 않는 고유한 값이다. 그리고 이 값을 후에 클라이언트에게 SSE 채널로 통신할 때 그 채널을 찾기 위해 사용하기 때문에 taskId를 메세지 값에 포함시켜서 보내주고 있는 상황이었다. 이 값은 사용자가 매 요청을 보낼 때마다 고유한 값이기 때문에 이 값을 잘 활용한다면 멱등성을 보장할 수 있다.<br />구현은 간단하다. 메시지를 처리하기 전 Redis나 DB에서 해당 taskId가 이미 처리되었는지 확인하고, 처리된 taskId라면 로직을 스킵하도록 하면 된다. 각 단계의 Agent가 taskId를 기준으로 현재 어느 단계까지 처리했는지를 Redis에 기록하고, 메시지가 들어올 때마다 확인하면, 중복 메시지가 들어와도 이미 처리된 단계는 무시할 수 있다. 이렇게 하면 Standard 큐 환경에서도 멱등성을 안정적으로 확보할 수 있으며, 동시에 각 Agent 단계별 진행 상황도 추적할 수 있다. 다만, 우리의 서비스에서는 하나의 taskId에 대해 3개의 version이 생성되므로 Redis에 저장할 때 키 값을 task:{taskId}:v{version}으로 문자열을 조합해서 생성하였다.</p><h4>Race Condition을 유의합시다</h4><p>만약 DB에 taskId별 진행 상황을 기록한다고 하면, 동시성 문제에 주의해야 한다. Standard 큐에서는 메시지가 중복으로 들어올 수 있고, Lambda가 스케일 아웃 되어 각각의 메시지를 동시에 처리할 수 있기 때문이다. 이런 상황에서 두 개 이상의 Lambda가 동시에 DB를 조회하면, 모두 “아직 처리되지 않았다”라고 판단하고 동시에 메시지를 발행하거나 update를 수행할 수 있다. 결과적으로 중복 처리가 발생할 위험이 존재한다.<br />이를 DB에서 안전하게 처리하기 위해서는 SELECT … FOR UPDATE 같은 X락을 사용해 트랜잭션을 직렬화해야 한다. 즉, 하나의 트랜잭션이 점유된 동안 다른 트랜잭션은 해당 행에 접근하지 못하도록 막는 방식이다. 이렇게 하면 멱등성이 보장되지만, 동시에 처리량이 크게 떨어지는 단점이 있다. 특히 트래픽이 폭주하는 생기부 생성 시즌에는 DB 병목으로 이어질 수 있다.<br />그래서 우리는 Redis를 활용한 상태 관리 방식을 선택했다. Redis는 기본적으로 싱글 스레드로 동작하며, key 단위로 원자적 연산을 지원한다. 덕분에 동시성 문제가 발생할 확률이 매우 낮고, 메시지가 중복되어 들어오더라도 Redis에 기록된 taskId 상태를 기준으로 처리 여부를 빠르게 판단할 수 있다. 또한 메모리 기반이라 조회와 업데이트 속도가 DB보다 훨씬 빠르며, 처리량이 많은 시기에도 안정적으로 동작한다.<br />결과적으로 taskId 기반 상태 추적을 Redis로 구현하면, Standard 큐 환경에서 발생할 수 있는 중복 메시지 문제를 자연스럽게 흡수하면서도, Lambda가 스케일 아웃되어도 멱등성을 안정적으로 보장할 수 있다.</p>